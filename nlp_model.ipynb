{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/usuario/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feelings = pd.read_excel('reviews_claro.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_feelings.copy()\n",
    "df = df[['at', 'content','score']]\n",
    "df = df.dropna(axis=0).reset_index(drop=True)\n",
    "df = df.rename(columns={'at': 'date', 'content': 'review'})\n",
    "df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tokenization(df):\n",
    "    corpus = []\n",
    "    for i in range(0, len(df)):\n",
    "        review = re.sub('[^a-zA-ZÀ-ÿ]', ' ', df['review'][i])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        ps = PorterStemmer()\n",
    "        all_stopwords = stopwords.words('spanish')\n",
    "        all_stopwords.remove('sí')\n",
    "        all_stopwords.remove('no')\n",
    "        all_stopwords.remove('ni')\n",
    "        review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = tokenization(df)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=4000)\n",
    "X = cv.fit_transform(dataset).toarray()\n",
    "y = df['score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use random forest classifier for easiness in application.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(n_estimators = 10, random_state=0)\n",
    "RF.fit(X_train, y_train)\n",
    "y_pred = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5411   100   131    45   370]\n",
      " [  832    53    79    23   147]\n",
      " [  557    54   116    54   427]\n",
      " [  247    30    91   123  1533]\n",
      " [  338    25    73   196 10449]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7511160714285714"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred) # 0.751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cv, open(\"count_vectorizer.pickle\", \"wb\"))\n",
    "pickle.dump(RF, open(\"RF_nlp.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento import create_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/pysentimiento/robertuito-sentiment-analysis/resolve/main/tokenizer.json from cache at /Users/usuario/.cache/huggingface/transformers/47dd2d3180a6186d30715516321375322e3a84d5e4656762e083091bbb5d5dc4.0843b07596b388e054bae078721182b4846b9e28a7bbf04d7079b274f8613ae3\n",
      "loading file https://huggingface.co/pysentimiento/robertuito-sentiment-analysis/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/pysentimiento/robertuito-sentiment-analysis/resolve/main/special_tokens_map.json from cache at /Users/usuario/.cache/huggingface/transformers/25e0e805456d2786a12b70b86278c6e839d19958cb4f541ee1f78621140098f7.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "loading file https://huggingface.co/pysentimiento/robertuito-sentiment-analysis/resolve/main/tokenizer_config.json from cache at /Users/usuario/.cache/huggingface/transformers/4fdf9a5a8e0a6023e1a9cdef62921158c3db9545e73f8dc0f46340a21bbb64d5.50a2bcf7668df2ff5a82b7b0455533bb4c0db21e6e33565fa20fd7dc8a3be740\n",
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-sentiment-analysis/resolve/main/config.json from cache at /Users/usuario/.cache/huggingface/transformers/034fd09e9530137fb6e6c042529972a92619fb02df8b40e7a4cfc50090943c46.98e658c5b8878c67807e3287b07db9608dbd08a5b69ce09979c447190bbe8077\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-sentiment-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEG\",\n",
      "    \"1\": \"NEU\",\n",
      "    \"2\": \"POS\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEG\": 0,\n",
      "    \"NEU\": 1,\n",
      "    \"POS\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30002\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-sentiment-analysis/resolve/main/pytorch_model.bin from cache at /Users/usuario/.cache/huggingface/transformers/46eaf2275c70a984feed87be9019d2c427e10e13e4498d391bedffc0c61b4991.01d3c05bd9b3f5c750a6a897fc7bc380ac6c30347fa348718ca5ed37b03fdd46\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/robertuito-sentiment-analysis.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AnalyzerOutput(output=NEU, probas={NEU: 0.977, POS: 0.020, NEG: 0.004}),\n",
       " AnalyzerOutput(output=POS, probas={POS: 0.976, NEU: 0.019, NEG: 0.004}),\n",
       " AnalyzerOutput(output=NEG, probas={NEG: 0.898, NEU: 0.074, POS: 0.028}))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict('Nutritivo y gordo'), analyzer.predict('excelente'), analyzer.predict('NO me gustó')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_sentimientos = analyzer.predict(corpus)\n",
    "output_sent = [pred.output for pred in pred_sentimientos]\n",
    "vec_sent = []\n",
    "for elem in output_sent:\n",
    "    if elem == 'POS':\n",
    "        vec_sent.append('positivo')\n",
    "    elif elem == 'NEG':\n",
    "        vec_sent.append('negativo')\n",
    "    else:\n",
    "        vec_sent.append('neutro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feeling'] = vec_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('db.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -e git+https://github.com/aylliote/senti-py#egg=senti-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-151-317e8402d430>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-151-317e8402d430>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import senti-py-masterrr\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import senti-py-masterrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n",
      "https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json not found in cache or force_download set to True, downloading to /Users/usuario/.cache/huggingface/transformers/tmpaddf5jpa\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa204267c8e4ddbbab906e67f7fd7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json in cache at /Users/usuario/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "creating metadata file for /Users/usuario/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /Users/usuario/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /Users/usuario/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /Users/usuario/.cache/huggingface/transformers/tmp_34buuob\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091f8f666c1e4be1897b3ea8a7af9059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/pytorch_model.bin in cache at /Users/usuario/.cache/huggingface/transformers/02f483764e26e1acfddfcd6e4879785f2908b2806a962d01b888bfe2b988075b.bd96a9432b167ab5e2b086cf0b688ca3c43c027091377eddfcfd39bdde851c35\n",
      "creating metadata file for /Users/usuario/.cache/huggingface/transformers/02f483764e26e1acfddfcd6e4879785f2908b2806a962d01b888bfe2b988075b.bd96a9432b167ab5e2b086cf0b688ca3c43c027091377eddfcfd39bdde851c35\n",
      "loading weights file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/pytorch_model.bin from cache at /Users/usuario/.cache/huggingface/transformers/02f483764e26e1acfddfcd6e4879785f2908b2806a962d01b888bfe2b988075b.bd96a9432b167ab5e2b086cf0b688ca3c43c027091377eddfcfd39bdde851c35\n",
      "All model checkpoint weights were used when initializing DistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of DistilBertForQuestionAnswering were initialized from the model checkpoint at distilbert-base-cased-distilled-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForQuestionAnswering for predictions without further training.\n",
      "https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /Users/usuario/.cache/huggingface/transformers/tmp_kdor_0n\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe53507833ab4b03992ce6d7a2131568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/tokenizer_config.json in cache at /Users/usuario/.cache/huggingface/transformers/b018780df739378fb3b8eec9c2c2c302c45fc3c3a74157f206cbc8db54229abf.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "creating metadata file for /Users/usuario/.cache/huggingface/transformers/b018780df739378fb3b8eec9c2c2c302c45fc3c3a74157f206cbc8db54229abf.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /Users/usuario/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /Users/usuario/.cache/huggingface/transformers/tmpbahbhi3l\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe648e587274fcea57e9b327232ceed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/vocab.txt in cache at /Users/usuario/.cache/huggingface/transformers/5e66e5f3d499a2fe36f07906eced96e223d283818c9a5fc17efd3e7bf4753711.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "creating metadata file for /Users/usuario/.cache/huggingface/transformers/5e66e5f3d499a2fe36f07906eced96e223d283818c9a5fc17efd3e7bf4753711.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /Users/usuario/.cache/huggingface/transformers/tmprugna7mj\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38aa86180d9041dfb5d4b70d4c0c6f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/tokenizer.json in cache at /Users/usuario/.cache/huggingface/transformers/3b10caec238c150efa989f0540fb8a3876bc7e010fe50aa9d7a9d42c84fc0587.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97\n",
      "creating metadata file for /Users/usuario/.cache/huggingface/transformers/3b10caec238c150efa989f0540fb8a3876bc7e010fe50aa9d7a9d42c84fc0587.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97\n",
      "loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/vocab.txt from cache at /Users/usuario/.cache/huggingface/transformers/5e66e5f3d499a2fe36f07906eced96e223d283818c9a5fc17efd3e7bf4753711.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/tokenizer.json from cache at /Users/usuario/.cache/huggingface/transformers/3b10caec238c150efa989f0540fb8a3876bc7e010fe50aa9d7a9d42c84fc0587.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97\n",
      "loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/tokenizer_config.json from cache at /Users/usuario/.cache/huggingface/transformers/b018780df739378fb3b8eec9c2c2c302c45fc3c3a74157f206cbc8db54229abf.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /Users/usuario/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.3097020387649536,\n",
       " 'start': 34,\n",
       " 'end': 58,\n",
       " 'answer': 'huggingface/transformers'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Allocate a pipeline for question-answering\n",
    "question_answerer = pipeline('question-answering')\n",
    "question_answerer({'question': 'What is the name of the repository ?', 'context': 'Pipeline has been included in the huggingface/transformers repository'})\n",
    "#{'score': 0.30970096588134766, 'start': 34, 'end': 58, 'answer': 'huggingface/transformers'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
